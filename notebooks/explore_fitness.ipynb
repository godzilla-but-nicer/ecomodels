{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from networkx.algorithms.bipartite.basic import color\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from matplotlib.animation import FuncAnimation\n","import networkx as nx\n","import statsmodels.api as sm\n","from glob import glob\n","from GLVsim import GLV\n","from sklearn.decomposition import PCA\n","\n","# change global plotting params\n","import matplotlib as mpl\n","font = {'family' : 'normal',\n","        'weight' : 'normal',\n","        'size'   : 14}\n","mpl.rc('font', **font)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Fitness\n"," ## Fitness Over Time\n"," First we just need to make sure that fitness actually went up otherwise\n"," what are we even doing here?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_list = []\n","for file in glob('../data/complete/fitness*.csv'):\n","    df_single = pd.read_csv(file)\n","    times = df_single['time'].values\n","    df_list.append(df_single.drop('time', axis = 1).values)\n","\n","fitnesses = np.array(df_list).mean(axis=0)[:, :-1]\n","avg_fit = fitnesses.mean(axis=1)\n","max_fit = fitnesses.max(axis=1)\n","plt.figure(figsize=(5,4))\n","plt.plot(times, fitnesses, c='grey', alpha=0.2)\n","\n","plt.plot(times, avg_fit, c='C0', label = 'Average')\n","plt.plot(times, max_fit, c='C1', label = 'Max')\n","plt.legend()\n","plt.xlabel('GA Tournaments')\n","plt.ylabel('Average Species Richness')\n","plt.tight_layout()\n","plt.savefig('../figures/fitness.png')\n","plt.savefig('../figures/fitness.pdf')\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Fitness Residuals\n"," Hell yeah. We also want to make sure that mean fitness is actually a good description\n"," of the tendency of our system. Let's double check that"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["residuals = (fitnesses.T - avg_fit).flatten()\n","sns.histplot(residuals)\n","plt.xlabel('Residual fitness')\n","plt.savefig('../figures/residual-fitness.png')\n","plt.savefig('../figures/residual-fitness.pdf')\n",""]},{"cell_type":"markdown","metadata":{},"source":[" It looks pretty good like we have a normal-ish distribution. So we can use\n"," the mean to characterize the tendancy."]},{"cell_type":"markdown","metadata":{},"source":[" # Demo Time Series\n"," We're going to want to put some little example timeseries in the paper. Is my\n"," library installed? First we'll get the lowest fitness network than the highest\n"," it might be cool to run each of these like a bunch of times and see where they\n"," end up in pca space."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# lowest fitness indices\n","low_fit = np.where(fitnesses == np.min(fitnesses))\n","low_time = times[low_fit[0]][0]\n","low_indiv = low_fit[1][0]\n","\n","# pull the lowest fitness network\n","low_adj = np.loadtxt('../data/complete/networks1/{}/{}_adjmat_10.csv'.format(low_time, low_indiv), delimiter=',')\n","np.fill_diagonal(low_adj, 1)\n","\n","# highest fitnesses indices\n","high_fit = np.where(fitnesses == np.max(fitnesses))\n","high_time = times[high_fit[0]][0]\n","high_indiv = high_fit[1][0]\n","\n","# pull the lowest fitness network\n","high_adj = np.loadtxt('../data/complete/networks1/{}/{}_adjmat_10.csv'.format(high_time, high_indiv), delimiter=',')\n","np.fill_diagonal(high_adj, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# params\n","num_weights = 45\n","runs = 20\n","low_vecs = np.zeros((num_weights * runs, 10))\n","high_vecs = np.zeros((num_weights * runs, 10))\n","labels = np.hstack((np.repeat([0], runs), np.repeat([1], runs)))\n","weights = -np.random.exponential(size=(num_weights, 10, 10))\n","ri = np.random.uniform(size=(runs, 10))\n","\n","for w in range(num_weights):\n","    # loop for each set of weights\n","    for i in range(runs):\n","        # low sim\n","        glv.set_state(ri[i])\n","        glv.set_matrix(low_adj * weights[w])\n","        _, ls = glv.simulate(50, 0.01)\n","        low_vecs[runs * w + i] = ls[-1]\n","\n","        # high vecs\n","        glv.set_state(ri[i])\n","        glv.set_matrix(high_adj * weights[w])\n","        _, hs = glv.simulate(50, 0.01)\n","        high_vecs[runs * w + i] = hs[-1]\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vecs = np.vstack((low_vecs, high_vecs))\n","pca = PCA()\n","vecs_pca = pca.fit_transform(vecs)\n","\n","\n","# lets make some plots\n","expvar = pca.explained_variance_ / np.sum(pca.explained_variance_)\n","ev_cs = np.cumsum(expvar)\n","\n","fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n","\n","# run to highlight\n","wi = 25\n","ii = 10\n","\n","# regular old PCA plot\n","ax[1].axvline(0, linestyle='--', color='grey', alpha=0.2)\n","ax[1].axhline(0, linestyle='--', color='grey', alpha=0.2)\n","ax[1].scatter(vecs_pca[runs * num_weights:, 0], vecs_pca[runs * num_weights:, 1], \n","              label='High Fitness', marker='x', alpha=0.6, facecolor='C1', edgecolor='C1')\n","ax[1].scatter(vecs_pca[:runs * num_weights, 0], vecs_pca[:runs * num_weights, 1], label='Low Fitness', \n","              alpha=0.6, facecolor='none', edgecolor='C0')\n","ax[1].scatter(vecs_pca[runs * num_weights + (wi * runs + ii), 0], \n","              vecs_pca[runs * num_weights + (wi * runs + ii), 1], s=500, \n","              facecolor='none', edgecolor='black')\n","ax[1].set_xlabel('PC1 ({:.1f}%)'.format(expvar[0] * 100))\n","ax[1].set_ylabel('PC2 ({:.1f}%)'.format(expvar[1] * 100))\n","ax[1].legend()\n","\n","# explained variance plot\n","# ax[1].bar(range(expvar.shape[0]), expvar, color='grey')\n","# ax[1].step(range(expvar.shape[0]), ev_cs, color='k')\n","# ax[1].set_xticks(range(expvar.shape[0]))\n","# ax[1].set_xlabel('Component #')\n","# ax[1].set_ylabel('Variance Explained (%)')\n","\n","# example time series plot\n","glv = GLV(10)\n","glv.set_matrix(high_adj * weights[wi])\n","glv.set_state(ri[ii])\n","lt, ls = glv.simulate(40, 0.01)\n","ax[0].plot(lt, ls)\n","ax[0].set_xlabel('Time')\n","ax[0].set_ylabel('Species Abundance')\n","\n","plt.tight_layout()\n","plt.savefig('../figures/pca.pdf')\n","plt.savefig('../figures/pca.png')\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}